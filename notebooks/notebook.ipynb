{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6ab43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = r\"../data/at-dataset/Scats_Data.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "df[[\"Detector_ID\", \"Lane\"]] = df[\"Detector\"].str.split(\"-\", expand=True)\n",
    "df = df.drop(columns=[\"Detector\"])\n",
    "df[\"Detector_ID\"] = pd.to_numeric(df[\"Detector_ID\"], errors=\"coerce\")\n",
    "df[\"Lane\"] = pd.to_numeric(df[\"Lane\"], errors=\"coerce\")\n",
    "df[\"DateTime\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"Detector_ID\", \"Lane\", \"DateTime\"])\n",
    "# df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "# df['Time'] = pd.to_datetime(df['Time'], format='%H:%M').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ea49ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invalid</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Detector_ID</th>\n",
       "      <th>Lane</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.268714e+06</td>\n",
       "      <td>1.268714e+06</td>\n",
       "      <td>1.268714e+06</td>\n",
       "      <td>1.268714e+06</td>\n",
       "      <td>1268714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.868234e-01</td>\n",
       "      <td>1.241695e+02</td>\n",
       "      <td>2.184701e+03</td>\n",
       "      <td>7.205200e+00</td>\n",
       "      <td>2024-04-14 22:37:38.667910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>2.061000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2023-08-23 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>2.257000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2024-04-14 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.920000e+02</td>\n",
       "      <td>2.257000e+03</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2024-12-03 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.498000e+03</td>\n",
       "      <td>2.402000e+03</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>2025-07-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.590651e+00</td>\n",
       "      <td>1.389751e+02</td>\n",
       "      <td>1.396438e+02</td>\n",
       "      <td>4.670805e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Invalid        Volume   Detector_ID          Lane  \\\n",
       "count  1.268714e+06  1.268714e+06  1.268714e+06  1.268714e+06   \n",
       "mean   5.868234e-01  1.241695e+02  2.184701e+03  7.205200e+00   \n",
       "min    0.000000e+00  0.000000e+00  2.013000e+03  1.000000e+00   \n",
       "25%    0.000000e+00  1.600000e+01  2.061000e+03  3.000000e+00   \n",
       "50%    0.000000e+00  7.200000e+01  2.257000e+03  6.000000e+00   \n",
       "75%    0.000000e+00  1.920000e+02  2.257000e+03  1.000000e+01   \n",
       "max    2.400000e+01  1.498000e+03  2.402000e+03  1.900000e+01   \n",
       "std    2.590651e+00  1.389751e+02  1.396438e+02  4.670805e+00   \n",
       "\n",
       "                            DateTime  \n",
       "count                        1268714  \n",
       "mean   2024-04-14 22:37:38.667910400  \n",
       "min              2023-01-01 00:00:00  \n",
       "25%              2023-08-23 20:00:00  \n",
       "50%              2024-04-14 06:00:00  \n",
       "75%              2024-12-03 03:00:00  \n",
       "max              2025-07-31 23:00:00  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788cc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         index  MissingEntries\n",
      "49   (2322, 6)             459\n",
      "48   (2322, 5)             459\n",
      "47   (2322, 4)             459\n",
      "46   (2322, 3)             459\n",
      "45   (2322, 2)             459\n",
      "44   (2322, 1)             459\n",
      "43  (2257, 19)             459\n",
      "42  (2257, 18)             459\n",
      "41  (2257, 17)             459\n",
      "40  (2257, 16)             459\n",
      "39  (2257, 15)             459\n",
      "38  (2257, 14)             459\n",
      "37  (2257, 13)             459\n",
      "36  (2257, 12)             459\n",
      "35  (2257, 11)             459\n",
      "34  (2257, 10)             459\n",
      "33   (2257, 9)             459\n",
      "32   (2257, 8)             459\n",
      "31   (2257, 7)             459\n",
      "30   (2257, 6)             459\n",
      "29   (2257, 5)             459\n",
      "28   (2257, 4)             459\n",
      "27   (2257, 3)             459\n",
      "26   (2257, 2)             459\n",
      "25   (2257, 1)             459\n",
      "8    (2013, 9)             435\n",
      "7    (2013, 8)             435\n",
      "6    (2013, 7)             435\n",
      "5    (2013, 6)             435\n",
      "4    (2013, 5)             435\n",
      "3    (2013, 4)             435\n",
      "2    (2013, 3)             435\n",
      "1    (2013, 2)             435\n",
      "0    (2013, 1)             435\n",
      "11  (2013, 12)             435\n",
      "10  (2013, 11)             435\n",
      "9   (2013, 10)             435\n",
      "12  (2013, 13)             435\n",
      "15   (2061, 3)             220\n",
      "14   (2061, 2)             220\n",
      "13   (2061, 1)             220\n",
      "24  (2061, 12)             220\n",
      "23  (2061, 11)             220\n",
      "22  (2061, 10)             220\n",
      "21   (2061, 9)             220\n",
      "20   (2061, 8)             220\n",
      "19   (2061, 7)             220\n",
      "18   (2061, 6)             220\n",
      "17   (2061, 5)             220\n",
      "16   (2061, 4)             220\n",
      "50   (2402, 1)             220\n",
      "51   (2402, 2)             220\n",
      "52   (2402, 3)             220\n",
      "53   (2402, 4)             220\n",
      "54   (2402, 6)             220\n",
      "55   (2402, 7)             220\n",
      "56   (2402, 8)             220\n"
     ]
    }
   ],
   "source": [
    "# ## check missing entry\n",
    "# full_time_index = pd.date_range(\n",
    "#     start=df[\"DateTime\"].min(),\n",
    "#     end=df[\"DateTime\"].max(),\n",
    "#     freq=\"h\"\n",
    "# )\n",
    "\n",
    "# missing_summary = {}\n",
    "\n",
    "# for (det, lane), group in df.groupby([\"Detector_ID\", \"Lane\"]):\n",
    "#     group = group.set_index(\"DateTime\").sort_index()\n",
    "#     # Drop duplicate DateTime entries to avoid reindex error\n",
    "#     group = group[~group.index.duplicated(keep='first')]\n",
    "#     reindexed = group.reindex(full_time_index)\n",
    "    \n",
    "#     n_missing = reindexed[\"Volume\"].isna().sum()\n",
    "#     if n_missing > 0:\n",
    "#         missing_summary[(det, lane)] = n_missing\n",
    "\n",
    "\n",
    "# missing_df = pd.DataFrame.from_dict(\n",
    "#     missing_summary, orient=\"index\", columns=[\"MissingEntries\"]\n",
    "# ).reset_index()\n",
    "# missing_df.rename(columns={\"level_0\": \"DetectorID\", \"level_1\": \"Lane\"}, inplace=True)\n",
    "\n",
    "# print(missing_df.sort_values(\"MissingEntries\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b6c2750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Detector_ID  Lane\n",
       "2013         1       22197\n",
       "             2       22197\n",
       "             3       22197\n",
       "             4       22197\n",
       "             5       22197\n",
       "             6       22197\n",
       "             7       22197\n",
       "             8       22197\n",
       "             9       22197\n",
       "             10      22197\n",
       "             11      22197\n",
       "             12      22197\n",
       "             13      22197\n",
       "2061         1       22412\n",
       "             2       22412\n",
       "             3       22412\n",
       "             4       22412\n",
       "             5       22412\n",
       "             6       22412\n",
       "             7       22412\n",
       "             8       22412\n",
       "             9       22412\n",
       "             10      22412\n",
       "             11      22412\n",
       "             12      22412\n",
       "2257         1       22173\n",
       "             2       22173\n",
       "             3       22173\n",
       "             4       22173\n",
       "             5       22173\n",
       "             6       22173\n",
       "             7       22173\n",
       "             8       22173\n",
       "             9       22173\n",
       "             10      22173\n",
       "             11      22173\n",
       "             12      22173\n",
       "             13      22173\n",
       "             14      22173\n",
       "             15      22173\n",
       "             16      22173\n",
       "             17      22173\n",
       "             18      22173\n",
       "             19      22173\n",
       "2322         1       22173\n",
       "             2       22173\n",
       "             3       22173\n",
       "             4       22173\n",
       "             5       22173\n",
       "             6       22173\n",
       "2402         1       22412\n",
       "             2       22412\n",
       "             3       22412\n",
       "             4       22412\n",
       "             6       22412\n",
       "             7       22412\n",
       "             8       22412\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Detector_ID\", \"Lane\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16292477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: 2061, Lane Number: [ 7  4 12  2 11  3  6  1  8 10  9  5]\n",
      "Site: 2402, Lane Number: [6 3 8 7 4 1 2]\n",
      "Site: 2257, Lane Number: [ 6  4  3  8  9 18 17  5 13 16 10  2 15  7 12 14  1 19 11]\n",
      "Site: 2013, Lane Number: [ 8 13  9  4  2  3  7 12  5 10  1 11  6]\n",
      "Site: 2322, Lane Number: [5 3 4 2 6 1]\n"
     ]
    }
   ],
   "source": [
    "site_list = df['Detector_ID'].unique()\n",
    "main_df = pd.DataFrame()\n",
    "for site in site_list:\n",
    "    lane_list = df[df['Detector_ID'] == site]['Lane'].unique()\n",
    "    df_lane_list = pd.DataFrame()\n",
    "    for lane in lane_list:\n",
    "        full_time_index = pd.date_range(\n",
    "            start=df[\"DateTime\"].min(),\n",
    "            end=df[\"DateTime\"].max(),\n",
    "            freq=\"h\"\n",
    "        )\n",
    "\n",
    "        interpolate_df = pd.DataFrame(index=full_time_index)\n",
    "        interpolate_df = interpolate_df.reset_index().rename(columns={'index': 'DateTime'})\n",
    "        interpolate_df['Detector_ID'] = site\n",
    "        interpolate_df['Lane'] = lane\n",
    "        interpolate_df['Traffic_Volume'] = df[(df['Detector_ID'] == site) & (df['Lane'] == lane)]['Traffic_Volume'].values\n",
    "        interpolate_df.sort_values('DateTime')\n",
    "        interpolate_df = interpolate_df.interpolate(method='time')\n",
    "        df_lane_list = pd.concat([df_lane_list, interpolate_df])\n",
    "    main_df = pd.concat([main_df, df_lane_list])\n",
    "\n",
    "\n",
    "\n",
    "    # site_data = df[df['Detector_ID'] == site]\n",
    "    # site_data.sort_values('DateTime')\n",
    "    # site_lane1 = site_data[site_data['Lane'] == 1]\n",
    "    # site_lane1 = site_lane1.set_index('DateTime').sort_index()\n",
    "\n",
    "\n",
    "\n",
    "    # missing_df = pd.DataFrame(full_time_index, columns=['DateTime'])\n",
    "    # missing_df['Missing'] = missing_df['DateTime'].apply(lambda x: x not in site_lane1.index)\n",
    "    # missing_date = missing_df[missing_df['Missing'] == True]['DateTime']\n",
    "    # missing_date = pd.DataFrame(missing_date)\n",
    "\n",
    "    # missing_date['Date'] = missing_date['DateTime'].dt.date\n",
    "    # missing_date.groupby('Date').size()\n",
    "    # # store missing date into csv\n",
    "    # missing_date.to_csv(f'../data/at-dataset/missing_dates_{site}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b6beff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_list = df['Detector_ID'].unique()\n",
    "full_time_index = pd.date_range(df[\"DateTime\"].min(), df[\"DateTime\"].max(), freq=\"h\")\n",
    "\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "for site in site_list:\n",
    "    lane_list = df.loc[df['Detector_ID'] == site, 'Lane'].unique()\n",
    "    df_lane_list = pd.DataFrame()\n",
    "    for lane in lane_list:\n",
    "        # base hourly frame for this site/lane\n",
    "        interpolate_df = (\n",
    "            pd.DataFrame(index=full_time_index)\n",
    "            .rename_axis('DateTime')\n",
    "            .reset_index()\n",
    "        )\n",
    "        interpolate_df['Detector_ID'] = site\n",
    "        interpolate_df['Lane'] = lane\n",
    "\n",
    "        # take the actual observations for this site/lane\n",
    "        sub = df[(df['Detector_ID'] == site) & (df['Lane'] == lane)][\n",
    "            ['DateTime', 'Volume']\n",
    "        ].copy()\n",
    "\n",
    "        # merge to align values to the hourly grid\n",
    "        interpolate_df = interpolate_df.merge(\n",
    "            sub, on='DateTime', how='left'\n",
    "        )\n",
    "\n",
    "        # set DateTime index for time-aware interpolation\n",
    "        interpolate_df = interpolate_df.sort_values('DateTime').set_index('DateTime')\n",
    "\n",
    "        # time-aware interpolation (add a limit if you want only short gaps filled)\n",
    "        interpolate_df['Volume'] = interpolate_df['Volume'].interpolate(\n",
    "            method='time'  #, limit=6\n",
    "        )\n",
    "\n",
    "        # back to rows\n",
    "        interpolate_df = interpolate_df.reset_index()\n",
    "\n",
    "        df_lane_list = pd.concat([df_lane_list, interpolate_df], ignore_index=True)\n",
    "\n",
    "    main_df = pd.concat([main_df, df_lane_list], ignore_index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
